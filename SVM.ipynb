{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM17luI6OoOYCYT1tPvbDjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HillaryDrugs/li7/blob/main/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs9VA87M3pov",
        "outputId": "c3885fa0-3d31-43fd-889f-c7cc766b6777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 1: Loading SMS Spam dataset\n",
            "======================================================================\n",
            "First 5 rows of the dataset:\n",
            "  label                                               text\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro... \n",
            "\n",
            "Total messages: 5572\n",
            "Unique labels: ['ham' 'spam']\n",
            "\n",
            "Example HAM message:\n",
            "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\n",
            "Example SPAM message:\n",
            "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "\n",
            "======================================================================\n",
            "STEP 2: Split into train and test sets\n",
            "======================================================================\n",
            "Training set size: 4457 messages\n",
            "Test set size:     1115 messages\n",
            "Training spam count: 598 / 4457\n",
            "Test spam count:     149 / 1115\n",
            "\n",
            "======================================================================\n",
            "STEP 3: The SVM - Finding the best separating boundary\n",
            "======================================================================\n",
            "\n",
            "We are building a text classifier:\n",
            "- 'ham'  = normal message\n",
            "- 'spam' = unwanted ad / scam\n",
            "\n",
            "Pipeline:\n",
            "1. TF-IDF turns each SMS into numeric features\n",
            "2. Linear SVM draws a boundary between ham and spam\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STEP 4: Training the SVM on spam vs ham\n",
            "======================================================================\n",
            "Training in progress...\n",
            "âœ“ Training complete!\n",
            "\n",
            "======================================================================\n",
            "STEP 5: Testing - How well did it learn?\n",
            "======================================================================\n",
            "\n",
            "ACCURACY: 98.12%\n",
            "(Got 1094 out of 1115 correct)\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "                    Predicted HAM (0)    Predicted SPAM (1)\n",
            "Actually HAM (0):           964                   2\n",
            "Actually SPAM (1):           19                 130\n",
            "\n",
            "DETAILED CLASSIFICATION REPORT:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "HAM (not spam)       0.98      1.00      0.99       966\n",
            "          SPAM       0.98      0.87      0.93       149\n",
            "\n",
            "      accuracy                           0.98      1115\n",
            "     macro avg       0.98      0.94      0.96      1115\n",
            "  weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "======================================================================\n",
            "STEP 6: Try with brand new messages\n",
            "======================================================================\n",
            "Message: WIN a brand new iPhone! Reply YES to claim your prize now!!!\n",
            "Prediction: SPAM ðŸš¨\n",
            "\n",
            "Message: Hey are we still meeting at 7 or should I come later?\n",
            "Prediction: HAM âœ…\n",
            "\n",
            "Message: URGENT! Your account is compromised. Click this link immediately to verify.\n",
            "Prediction: SPAM ðŸš¨\n",
            "\n",
            "Message: Ok I'm home, text me when you arrive.\n",
            "Prediction: HAM âœ…\n",
            "\n",
            "Message: You have won $5000 cash. Call now to receive your reward.\n",
            "Prediction: SPAM ðŸš¨\n",
            "\n",
            "======================================================================\n",
            "STEP 7: What words scream SPAM vs HAM?\n",
            "======================================================================\n",
            "\n",
            "In a linear SVM:\n",
            "- Positive weight  -> pushes toward class 1 (SPAM)\n",
            "- Negative weight  -> pushes toward class 0 (HAM)\n",
            "\n",
            "We're going to inspect the learned weights.\n",
            "\n",
            "\n",
            "TOP 15 SPAM WORDS (high => more likely SPAM):\n",
            "  'uk': 2.7323\n",
            "  'txt': 2.5897\n",
            "  'mobile': 2.2561\n",
            "  '150p': 2.1479\n",
            "  'www': 2.0176\n",
            "  'claim': 1.9113\n",
            "  'service': 1.8733\n",
            "  'ringtone': 1.7710\n",
            "  '50': 1.6761\n",
            "  'reply': 1.6315\n",
            "  'new voicemail': 1.6142\n",
            "  'http': 1.6116\n",
            "  'com': 1.5286\n",
            "  'new message': 1.5227\n",
            "  'prize': 1.5221\n",
            "\n",
            "TOP 15 HAM WORDS (low => more likely normal / HAM):\n",
            "  'does': -0.6079\n",
            "  'alright': -0.6600\n",
            "  'did': -0.6695\n",
            "  'awesome': -0.6739\n",
            "  'place': -0.6866\n",
            "  'sorry': -0.6941\n",
            "  'said': -0.7171\n",
            "  'lunch': -0.7277\n",
            "  'later': -0.7308\n",
            "  'machan': -0.7426\n",
            "  'hey': -0.7738\n",
            "  'yup': -0.7769\n",
            "  'gonna': -0.7797\n",
            "  'home': -0.8281\n",
            "  'mail': -0.9822\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 0: IMPORTS\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: LOAD THE DATASET\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 1: Loading SMS Spam dataset\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding=\"cp1252\")\n",
        "\n",
        "# Keep only useful columns\n",
        "df = df[[\"v1\", \"v2\"]].rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
        "\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head(), \"\\n\")\n",
        "\n",
        "print(f\"Total messages: {len(df)}\")\n",
        "print(f\"Unique labels: {df['label'].unique()}\")\n",
        "\n",
        "# Map labels to numeric for reporting:\n",
        "# ham  -> 0\n",
        "# spam -> 1\n",
        "label_map = {\"ham\": 0, \"spam\": 1}\n",
        "df[\"label_num\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "texts = df[\"text\"].tolist()\n",
        "labels = df[\"label_num\"].tolist()\n",
        "\n",
        "print(\"\\nExample HAM message:\")\n",
        "print(df[df['label'] == 'ham']['text'].iloc[0])\n",
        "\n",
        "print(\"\\nExample SPAM message:\")\n",
        "print(df[df['label'] == 'spam']['text'].iloc[0])\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: TRAIN / TEST SPLIT\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 2: Split into train and test sets\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,        # 20% test\n",
        "    random_state=42,      # reproducible\n",
        "    stratify=labels       # preserve ham/spam ratio\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} messages\")\n",
        "print(f\"Test set size:     {len(X_test)} messages\")\n",
        "print(f\"Training spam count: {sum(y_train)} / {len(y_train)}\")\n",
        "print(f\"Test spam count:     {sum(y_test)} / {len(y_test)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: BUILD THE SVM CLASSIFIER\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 3: The SVM - Finding the best separating boundary\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\"\"\n",
        "We are building a text classifier:\n",
        "- 'ham'  = normal message\n",
        "- 'spam' = unwanted ad / scam\n",
        "\n",
        "Pipeline:\n",
        "1. TF-IDF turns each SMS into numeric features\n",
        "2. Linear SVM draws a boundary between ham and spam\n",
        "\"\"\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_features=5000,      # allow rich vocabulary\n",
        "        min_df=2,               # ignore words that appear only once\n",
        "        ngram_range=(1, 2),     # use 1-word and 2-word phrases\n",
        "        stop_words='english'    # remove common filler words\n",
        "    )),\n",
        "    ('svm', SVC(\n",
        "        kernel='linear',        # linear SVM works very well for text\n",
        "        C=1.0,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: TRAIN THE MODEL\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 4: Training the SVM on spam vs ham\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"Training in progress...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"âœ“ Training complete!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: EVALUATE THE MODEL\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 5: Testing - How well did it learn?\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "predictions = pipeline.predict(X_test)\n",
        "\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(f\"\\nACCURACY: {accuracy * 100:.2f}%\")\n",
        "print(f\"(Got {sum(predictions == y_test)} out of {len(y_test)} correct)\\n\")\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(\"CONFUSION MATRIX:\")\n",
        "print(\"                    Predicted HAM (0)    Predicted SPAM (1)\")\n",
        "print(f\"Actually HAM (0):          {cm[0][0]:4d}                {cm[0][1]:4d}\")\n",
        "print(f\"Actually SPAM (1):         {cm[1][0]:4d}                {cm[1][1]:4d}\")\n",
        "print()\n",
        "\n",
        "print(\"DETAILED CLASSIFICATION REPORT:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    predictions,\n",
        "    target_names=['HAM (not spam)', 'SPAM']\n",
        "))\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: TRY IT ON NEW MESSAGES\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 6: Try with brand new messages\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "new_messages = [\n",
        "    \"WIN a brand new iPhone! Reply YES to claim your prize now!!!\",\n",
        "    \"Hey are we still meeting at 7 or should I come later?\",\n",
        "    \"URGENT! Your account is compromised. Click this link immediately to verify.\",\n",
        "    \"Ok I'm home, text me when you arrive.\",\n",
        "    \"You have won $5000 cash. Call now to receive your reward.\"\n",
        "]\n",
        "\n",
        "for msg in new_messages:\n",
        "    pred = pipeline.predict([msg])[0]\n",
        "    label_text = \"SPAM ðŸš¨\" if pred == 1 else \"HAM âœ…\"\n",
        "    print(f\"Message: {msg}\")\n",
        "    print(f\"Prediction: {label_text}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: INTERPRET THE MODEL (MOST SPAMMY WORDS)\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 7: What words scream SPAM vs HAM?\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\"\"\n",
        "In a linear SVM:\n",
        "- Positive weight  -> pushes toward class 1 (SPAM)\n",
        "- Negative weight  -> pushes toward class 0 (HAM)\n",
        "\n",
        "We're going to inspect the learned weights.\n",
        "\"\"\")\n",
        "\n",
        "# Get trained vectorizer + SVM\n",
        "tfidf_vectorizer = pipeline.named_steps['tfidf']\n",
        "svm_model = pipeline.named_steps['svm']\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# svm_model.coef_ might be sparse depending on backend.\n",
        "# We convert it to a dense flat numpy array so it's always printable.\n",
        "coef_matrix = svm_model.coef_\n",
        "\n",
        "# If it's sparse, make it dense\n",
        "if hasattr(coef_matrix, \"toarray\"):\n",
        "    coef_dense = coef_matrix.toarray()[0]\n",
        "else:\n",
        "    coef_dense = coef_matrix[0]\n",
        "\n",
        "# Now we have plain floats we can format\n",
        "word_weights = list(zip(feature_names, coef_dense))\n",
        "\n",
        "# Sort by weight descending:\n",
        "# high positive weight => more \"spammy\"\n",
        "word_weights_sorted = sorted(word_weights, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nTOP 15 SPAM WORDS (high => more likely SPAM):\")\n",
        "for word, weight in word_weights_sorted[:15]:\n",
        "    print(f\"  '{word}': {float(weight):.4f}\")\n",
        "\n",
        "print(\"\\nTOP 15 HAM WORDS (low => more likely normal / HAM):\")\n",
        "for word, weight in word_weights_sorted[-15:]:\n",
        "    print(f\"  '{word}': {float(weight):.4f}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}